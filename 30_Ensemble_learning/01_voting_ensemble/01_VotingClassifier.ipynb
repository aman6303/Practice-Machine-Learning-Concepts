{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "573b3fbc-8da9-49c0-856e-93c829b0827e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Accuracy: 0.8700\n",
      "Ensemble Log Loss: 0.3362\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "# 1. Generate synthetic dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 2. Define Base Learners with Specific Preprocessing\n",
    "# Model A: Logistic Regression (Requires Scaling)\n",
    "clf1 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('lr', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Model B: Random Forest (Does NOT require scaling)\n",
    "# We use it directly as it handles raw data well\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Model C: SVM (Requires Scaling + Explicit Probability)\n",
    "# Note: SVC does not output probabilities by default. We must set probability=True\n",
    "clf3 = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('svc', SVC(kernel='rbf', probability=True, random_state=42))\n",
    "])\n",
    "\n",
    "# 3. Initialize the Voting Classifier (Soft Voting)\n",
    "# We assign arbitrary initial weights. We will tune these later.\n",
    "eclf = VotingClassifier(\n",
    "    estimators=[('lr', clf1), ('rf', clf2), ('svc', clf3)],\n",
    "    voting='soft', \n",
    "    weights=[1, 1, 1] \n",
    ")\n",
    "\n",
    "# 4. Fit the Ensemble\n",
    "eclf.fit(X_train, y_train)\n",
    "\n",
    "# 5. Evaluation\n",
    "y_pred = eclf.predict(X_test)\n",
    "y_prob = eclf.predict_proba(X_test)\n",
    "\n",
    "print(f\"Ensemble Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"Ensemble Log Loss: {log_loss(y_test, y_prob):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516f0476-1ddf-4884-9f8a-e179498aa4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
